{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import sigkernel\n",
    "import os\n",
    "import sys\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "import ksig\n",
    "from tqdm import tqdm\n",
    "\n",
    "from kernels.abstract_base import TimeSeriesKernel, StaticKernel\n",
    "from kernels.static_kernels import LinearKernel, RBFKernel, PolyKernel\n",
    "from kernels.integral import StaticIntegralKernel\n",
    "from kernels.sig_pde import SigPDEKernel\n",
    "from kernels.sig_trunc import TruncSigKernel\n",
    "from kernels.gak import GlobalAlignmentKernel, sigma_gak\n",
    "\n",
    "from features.random_fourier import RBF_RandomFourierFeatures\n",
    "from features.random_sig_fourier import TRP_RFSF_Gaussian, TRP_RFSF_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'signatory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignatory\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msig\u001b[39m(\n\u001b[1;32m      8\u001b[0m     X: Tensor,\n\u001b[1;32m      9\u001b[0m     trunc_level: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     10\u001b[0m ):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Computes the truncated signature of time series of\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    shape (T,d) with optional batch support.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m            D = 1 + d + d^2 + ... + d^trunc_level.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'signatory'"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import signatory\n",
    "\n",
    "\n",
    "def sig(\n",
    "    X: Tensor,\n",
    "    trunc_level: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the truncated signature of time series of\n",
    "    shape (T,d) with optional batch support.\n",
    "    \n",
    "    Args:\n",
    "        X (Tensor): Tensor of shape (..., T, d) of time series.\n",
    "        trunc_level (int): Signature truncation level.\n",
    "    \n",
    "    Returns:\n",
    "        Tensor: Tensor of shape (..., D) where \n",
    "            D = 1 + d + d^2 + ... + d^trunc_level.\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact\n",
      " tensor([[ 2581.8730,  -235.9912],\n",
      "        [-2129.7358,  -272.5004],\n",
      "        [ 6718.6289,  -402.8711]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:14<00:00, 669.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      " tensor([[ 2396.6672,  -120.0564],\n",
      "        [-1895.8381,  -362.5847],\n",
      "        [ 6214.2769,   193.0739]], device='cuda:0')\n",
      "example\n",
      " tensor([[   247.9467,    763.2634],\n",
      "        [  1037.1696,   3726.6875],\n",
      "        [ -2612.9407, -10172.9092]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#### Linear TRP-RFSF features  vs  Vanilla Sig kernel ####\n",
    "##########################################################\n",
    "\n",
    "def LINEAR_trp_vs_kernel():\n",
    "    #parameters\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 20\n",
    "    d = 2\n",
    "    trunc_level = 5\n",
    "    n_features = d\n",
    "    dtype = torch.float32\n",
    "    #torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "\n",
    "    #exact sig kernel\n",
    "    sigker = TruncSigKernel(LinearKernel(), normalize=False, trunc_level=trunc_level, geo_order=1, max_batch=50000)\n",
    "    K = sigker(X,Y)\n",
    "    print(\"exact\\n\", K)\n",
    "\n",
    "    #trp\n",
    "    MC_iter = 10000\n",
    "    res = []\n",
    "    for i in tqdm(range(MC_iter)):\n",
    "        trp = TRP_RFSF_Linear(trunc_level, n_features, only_last=True)\n",
    "        feat_X = trp(X)\n",
    "        feat_Y = trp(Y)\n",
    "        K_trp = 1 + feat_X @ feat_Y.T\n",
    "        res.append(K_trp)\n",
    "    res = torch.stack(res)\n",
    "    example = res[0]\n",
    "    mean = res.mean(dim=0)\n",
    "    print(\"mean\\n\", mean)\n",
    "    print(\"example\\n\", example)\n",
    "\n",
    "# LINEAR_trp_vs_kernel()\n",
    "# # exact\n",
    "# #  tensor([[ 4627.0444, -5744.9629],\n",
    "# #         [ 9709.9150, -7802.3965],\n",
    "# #         [-1727.5579,  2563.8979]], device='cuda:0')\n",
    "# # 100%|██████████| 10000/10000 [00:15<00:00, 641.01it/s] # n_features = 500, trunc_level = 5\n",
    "# # mean\n",
    "# #  tensor([[ 4624.3896, -5737.0781],\n",
    "# #         [ 9733.1250, -7796.5479],\n",
    "# #         [-1733.9088,  2575.4778]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#### Gaussian TRP-RFSF features  vs  SigRBF kernel ####\n",
    "#######################################################\n",
    "\n",
    "def GAUSSIAN_trp_vs_kernel():\n",
    "    #parameters\n",
    "    N = 3\n",
    "    N2 = 2\n",
    "    T = 20\n",
    "    d = 2\n",
    "    trunc_level = 5\n",
    "    n_features = 5000\n",
    "    sigma = 1.0\n",
    "    dtype = torch.float32\n",
    "    #torch.manual_seed(3)\n",
    "    X = torch.randn(N, T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "    Y = torch.randn(N2,T, d, dtype=dtype).to(\"cuda\").detach() / np.sqrt(d)\n",
    "\n",
    "    #exact sig kernel\n",
    "    sigker = TruncSigKernel(RBFKernel(sigma=sigma), normalize=False, trunc_level=trunc_level, geo_order=1, max_batch=50000)\n",
    "    K = sigker(X,Y)\n",
    "    print(\"exact\\n\", K)\n",
    "\n",
    "    #trp\n",
    "    MC_iter = 10000\n",
    "    res = []\n",
    "    for i in tqdm(range(MC_iter)):\n",
    "        trp = TRP_RFSF_Gaussian(trunc_level, n_features, sigma, only_last=True)\n",
    "        feat_X = trp(X)\n",
    "        feat_Y = trp(Y)\n",
    "        K_trp = 1 + feat_X @ feat_Y.T\n",
    "        res.append(K_trp)\n",
    "    res = torch.stack(res)\n",
    "    example = res[0]\n",
    "    mean = res.mean(dim=0)\n",
    "    print(\"mean\\n\", mean)\n",
    "    print(\"example\\n\", example)\n",
    "\n",
    "# GAUSSIAN_trp_vs_kernel()\n",
    "# # exact\n",
    "# #  tensor([[ -8.7953, -30.1428],\n",
    "# #         [ -4.1622,  -4.5515],\n",
    "# #         [-25.4650,  42.8830]], device='cuda:0')\n",
    "# # 100%|██████████| 10000/10000 [05:55<00:00, 28.10it/s] # n_features=5000, trunc_level=5\n",
    "# # mean\n",
    "# #  tensor([[ -9.9236, -30.5771],\n",
    "# #         [ -4.4291,  -4.5940],\n",
    "# #         [-25.3243,  43.3625]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "#### Test RBF_RandomFourierFeatures vs exact RBF kernel ####\n",
    "############################################################\n",
    "def rff_vs_exact_RBFKernel():\n",
    "    N=3\n",
    "    N2= 2\n",
    "    d = 10\n",
    "    sigma=1\n",
    "    dtype = torch.float64\n",
    "    # torch.manual_seed(1)\n",
    "    X = torch.randn(N, d, dtype=dtype).to(\"cuda\") /np.sqrt(d)\n",
    "    Y = torch.randn(N2, d, dtype=dtype).to(\"cuda\") / np.sqrt(d)\n",
    "\n",
    "    # Exact RBF kernel\n",
    "    k = RBFKernel(sigma=sigma)\n",
    "    K = k(X, Y)\n",
    "\n",
    "    # Approximate RBF kernel using RBF_RandomFourierFeatures\n",
    "    N_MC = 10000\n",
    "    res = []\n",
    "    for i in range(N_MC):\n",
    "        RFF = RBF_RandomFourierFeatures(n_features=1000,\n",
    "                                        sigma=sigma,\n",
    "                                        method=\"cos(x)sin(x)\",\n",
    "                                        # method = \"cos(x + b)\",\n",
    "                                        )\n",
    "        feat_X = RFF(X)\n",
    "        feat_Y = RFF(Y)\n",
    "        K_rff = feat_X @ feat_Y.T\n",
    "        res.append(K_rff)\n",
    "    K_rff = torch.mean(torch.stack(res), dim=0)\n",
    "\n",
    "    print(\"K\\n\",K)\n",
    "    print(\"K_rff\\n\",K_rff)\n",
    "    print(\"diff\\n\", K-K_rff)\n",
    "    print(\"diffmean\\n\", torch.mean(abs(K-K_rff)))\n",
    "    # the RFF approach cant reproduce results smaller than 1e-5 for some reason\n",
    "    \n",
    "#rff_vs_exact_RBFKernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_X [[ 1.00000000e+00 -3.59423506e-03 -9.07996261e-02 ...  8.40732859e-01\n",
      "   5.30873379e+00  2.69755228e-01]\n",
      " [ 1.00000000e+00 -1.93983825e-02  5.37721907e-02 ... -4.71890160e+00\n",
      "   1.59428865e+00 -1.14701394e+00]\n",
      " [ 1.00000000e+00 -7.26373305e-02 -1.01710501e-03 ... -3.97536125e-01\n",
      "  -2.62673210e-01 -6.75785009e-01]]\n",
      "\n",
      "\n",
      "TRP XX\n",
      " [[259.35195906  -5.04945709  -0.91706391]\n",
      " [ -5.04945709 470.53149444  13.50306053]\n",
      " [ -0.91706391  13.50306053 183.76779889]]\n",
      "Exact XX\n",
      " [[266.96674815   6.09468627   6.73704003]\n",
      " [  6.09468627 417.85548768   4.0151835 ]\n",
      " [  6.73704003   4.0151835  164.36345817]]\n",
      "\n",
      "\n",
      "TRP XY\n",
      " [[  1.85705796  14.55856174  12.49293309  37.6238032 ]\n",
      " [ 69.12108422  21.17174776   4.64703248 -11.5869424 ]\n",
      " [ 15.17577528  -5.66409298   2.21091271   3.41681129]]\n",
      "Exact XY\n",
      " [[7.10066583 8.11644864 6.70422197 6.06963588]\n",
      " [8.21421106 5.85429156 5.74094593 6.56326078]\n",
      " [7.37560119 5.40776958 4.61642167 6.67836765]]\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "######### FROM KSIG LIBRARY #########\n",
    "#####################################\n",
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "def ksig_readme():\n",
    "    # Number of signature levels to use.\n",
    "    n_levels = 5 \n",
    "    normalize=False\n",
    "\n",
    "    # Use 100 components in RFF and projection.\n",
    "    n_components = 100\n",
    "\n",
    "    # Instantiate RFF feature map.\n",
    "    static_feat = ksig.static.features.RandomFourierFeatures(n_components=n_components)\n",
    "    # Instantiate tensor random projections.\n",
    "    proj = ksig.projections.TensorizedRandomProjection(n_components=n_components)\n",
    "\n",
    "    # The RFSF-TRP feature map and kernel. Additionally to working as a callable for\n",
    "    # computing a kernel, it implements a fit and a transform method.\n",
    "    rfsf_trp_kernel = ksig.kernels.SignatureFeatures(\n",
    "        n_levels=n_levels, static_features=static_feat, projection=proj, normalize=normalize)\n",
    "\n",
    "    # Generate 1000 sequences of length 200 with 100 features.\n",
    "    n_seq, l_seq, n_feat = 3, 20, 10\n",
    "    X = np.random.randn(n_seq, l_seq, n_feat) / np.sqrt(n_feat)\n",
    "\n",
    "    # Fit the kernel to the data.\n",
    "    rfsf_trp_kernel.fit(X)\n",
    "\n",
    "    # Compute the kernel matrix as before.\n",
    "    K_XX = rfsf_trp_kernel(X)  # K_XX has shape (1000, 1000).\n",
    "\n",
    "    # GEnerate another array of 800 sequences of length 250 and 100 features.\n",
    "    n_seq2, l_seq2 = 4, 20\n",
    "    Y = np.random.randn(n_seq2, l_seq2, n_feat) / np.sqrt(n_feat)\n",
    "\n",
    "    # Compute the kernel matrix between X and Y.\n",
    "    # The kernel does not have to be fitted a second time.\n",
    "    K_XY = rfsf_trp_kernel(X, Y)  # K_XY has shape (1000, 800)\n",
    "\n",
    "    # Alternatively, we may compute features separately for X and Y. Under the hood,\n",
    "    # this is what the call method does, i.e. compute features and take their inner product.\n",
    "    P_X = rfsf_trp_kernel.transform(X)  # P_X has shape (1000, 501)\n",
    "    P_Y = rfsf_trp_kernel.transform(Y)  # P_Y shape shape (800, 501)\n",
    "    print(\"P_X\", P_X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Use the RBF kernel for vector-valued data as static (base) kernel.\n",
    "    static_kernel = ksig.static.kernels.RBFKernel()\n",
    "    order = 1\n",
    "    sig_kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, static_kernel=static_kernel,\n",
    "                                              normalize=normalize)\n",
    "\n",
    "    # Sequence kernels take as input an array of sequences of ndim == 3,\n",
    "    # and work as a callable for computing the kernel matrix.\n",
    "    K_XX_exact = sig_kernel(X)\n",
    "    K_XY_exact = sig_kernel(X, Y)  \n",
    "    print(\"\\n\\nTRP XX\\n\", K_XX)\n",
    "    print(\"Exact XX\\n\", K_XX_exact)\n",
    "    print(\"\\n\\nTRP XY\\n\", K_XY)\n",
    "    print(\"Exact XY\\n\", K_XY_exact)\n",
    "\n",
    "ksig_readme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "## KSIG test TRP vs DP ##\n",
    "#########################\n",
    "import ksig\n",
    "import numpy as np\n",
    "\n",
    "def trp_vs_dp():\n",
    "    n_seq, l_seq, n_feat = 10, 150, 100\n",
    "    X = np.random.randn(n_seq, l_seq, n_feat)\n",
    "    n_levels = 10  # Number of signature levels to use.\n",
    "    n_components = 100 # Use dimension of RFF map\n",
    "\n",
    "    # Instantiate RFF feature map.\n",
    "    static_feat = ksig.static.features.RandomFourierFeatures(n_components=n_components)\n",
    "    trp_proj = ksig.projections.TensorizedRandomProjection(n_components=n_components)\n",
    "    dp_proj = ksig.projections.DiagonalProjection()\n",
    "\n",
    "    # The RFSF-TRP feature map and kernel. Additionally to working as a callable for\n",
    "    # computing a kernel, it implements a fit and a transform method.\n",
    "    trp_kernel = ksig.kernels.SignatureFeatures(\n",
    "        n_levels=n_levels, \n",
    "        static_features=static_feat, \n",
    "        projection=trp_proj\n",
    "        )\n",
    "    dp_kernel = ksig.kernels.SignatureFeatures(\n",
    "        n_levels=n_levels,\n",
    "        static_features=static_feat,\n",
    "        projection=dp_proj\n",
    "        )\n",
    "    trp_kernel.fit(X)\n",
    "    dp_kernel.fit(X)\n",
    "\n",
    "\n",
    "    # TIME IT\n",
    "    import timeit\n",
    "    def function_dp():\n",
    "        dp_kernel(X, X)\n",
    "    def function_trp():\n",
    "        trp_kernel(X, X)\n",
    "    execution_time_dp = timeit.timeit(function_dp, number=10)\n",
    "    print(\"Execution time of dp\\t:\", execution_time_dp)\n",
    "    execution_time_trp = timeit.timeit(function_trp, number=10)\n",
    "    print(\"Execution time of trp\\t:\", execution_time_trp)\n",
    "#trp_vs_dp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
