{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import sigkernel\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from kernels.abstract_base import TimeSeriesKernel, StaticKernel\n",
    "from kernels.static_kernels import LinearKernel, RBFKernel, PolyKernel\n",
    "from kernels.integral_type import IntegralKernel\n",
    "from kernels.sig_pde import SigPDEKernel\n",
    "from kernels.sig_trunc import TruncSigKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58441.3398])\n",
      "58441.349174799696 iisig\n"
     ]
    }
   ],
   "source": [
    "import ksig\n",
    "import iisignature\n",
    "####################   test mine vs ksig   ####################\n",
    "\n",
    "\n",
    "T = 7\n",
    "d = 5\n",
    "X = np.random.randn(2, T, d)\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)[0]\n",
    "# print(X)\n",
    "# print(X_torch)\n",
    "\n",
    "n_levels = 6\n",
    "order = 6\n",
    "# ksigker = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, static_kernel=ksig.static.kernels.LinearKernel(), \n",
    "#                                        normalize=False, difference=True)\n",
    "# out = ksigker(X, X)[0, 0]\n",
    "\n",
    "sigker = TruncSigKernel(static_kernel=LinearKernel(), trunc_level=n_levels, geo_order=order)\n",
    "out_torch = sigker(X_torch, X_torch)\n",
    "sig_features = iisignature.sig(X[0], n_levels)\n",
    "out_iisig = 1+np.dot(sig_features, sig_features)\n",
    "\n",
    "print(out_torch)\n",
    "#print(out, \"ksig\")\n",
    "print(out_iisig, \"iisig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand((7,6))\n",
    "print(A)\n",
    "A[:,:] = 1\n",
    "print(A)\n",
    "print(A[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kernel(kernel: TimeSeriesKernel):\n",
    "    print(\"Testing\", kernel)\n",
    "\n",
    "    gram = kernel.gram(X, Y)\n",
    "    diag = kernel.gram(X, Z, diag=True)\n",
    "    batch_call = kernel(X, Z)\n",
    "    call = kernel(X[0], Z[0])\n",
    "    print(\"gram\", gram.shape)\n",
    "    print(\"diag\", diag.shape)\n",
    "    print(\"batch_call\", batch_call.shape)\n",
    "    print(\"call\", call.shape, call)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "N1 = 5\n",
    "N2 = 6\n",
    "T = 7\n",
    "d = 3\n",
    "torch.manual_seed(0)\n",
    "X = torch.rand((N1, T, d), dtype=torch.float64)\n",
    "Y = torch.rand((N2, T, d), dtype=torch.float64)\n",
    "Z = torch.rand((N1, T, d), dtype=torch.float64)\n",
    "print(\"X\", X.shape)\n",
    "print(\"Y\", Y.shape)\n",
    "print(\"Z\", Z.shape)\n",
    "\n",
    "rbf = RBFKernel()\n",
    "integral = IntegralKernel(rbf)\n",
    "sigpde = SigPDEKernel(rbf)\n",
    "test_kernel(integral)\n",
    "test_kernel(sigpde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "# Number of signature levels to use.\n",
    "n_levels = 5 \n",
    "\n",
    "# Use the RBF kernel for vector-valued data as static (base) kernel.\n",
    "static_kernel = ksig.static.kernels.RBFKernel() \n",
    "\n",
    "# Instantiate the signature kernel, which takes as input the static kernel.\n",
    "n_levels = 5\n",
    "order = 1\n",
    "sig_kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, static_kernel=static_kernel)\n",
    "\n",
    "# Generate 10 sequences of length 50 with 5 channels.\n",
    "n_seq, l_seq, n_feat = 10, 50, 5 \n",
    "X = np.random.randn(n_seq, l_seq, n_feat)\n",
    "\n",
    "# Sequence kernels take as input an array of sequences of ndim == 3,\n",
    "# and work as a callable for computing the kernel matrix. \n",
    "K_XX = sig_kernel(X)  # K_XX has shape (10, 10).\n",
    "\n",
    "# The diagonal kernel entries can also be computed.\n",
    "K_X = sig_kernel(X, diag=True)  # K_X has shape (10,).\n",
    "\n",
    "# Generate another array of 8 sequences of length 20 and 5 features.\n",
    "n_seq2, l_seq2 = 8, 20\n",
    "Y = np.random.randn(n_seq2, l_seq2, n_feat)\n",
    "\n",
    "# Compute the kernel matrix between arrays X and Y.\n",
    "K_XY = sig_kernel(X, Y)  # K_XY has shape (10, 8)\n",
    "K_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_kernel(s1:Tensor, \n",
    "               s2:Tensor, \n",
    "               order:int,\n",
    "               static_kernel_gram:Callable = linear_kernel_gram,\n",
    "               only_last:bool = True):\n",
    "    \"\"\"Computes the truncated signature kernel of two time series of \n",
    "    shape (T_i, d) with respect to a static kernel on R^d.\n",
    "\n",
    "    Args:\n",
    "        s1 (np.ndarray): Array of shape (T_1, d).\n",
    "        s2 (np.ndarray): Array of shape (T_2, d).\n",
    "        order (int): Truncation order of the signature kernel.\n",
    "        static_kernel_gram (Callable): Gram kernel function taking in two ndarrays,\n",
    "                            see e.g. 'linear_kernel_gram' or 'rbf_kernel_gram'.\n",
    "        only_last (bool): If False, returns results of all truncation levels up to 'order'.\n",
    "    \"\"\"\n",
    "    K = static_kernel_gram(s1, s2)\n",
    "    nabla = K[1:, 1:] + K[:-1, :-1] - K[1:, :-1] - K[:-1, 1:]\n",
    "    sig_kers = jitted_trunc_sig_kernel(nabla, order)\n",
    "    if only_last:\n",
    "        return sig_kers[-1]\n",
    "    else:\n",
    "        return sig_kers\n",
    "\n",
    "\n",
    "\n",
    "@njit((nb.float64[:, ::1], nb.int64), fastmath=True, cache=True)\n",
    "def reverse_cumsum(arr:Tensor, axis:int): #ndim=2\n",
    "    \"\"\"JITed reverse cumulative sum along the specified axis.\n",
    "    (np.cumsum with axis is not natively supported by Numba)\n",
    "    \n",
    "    Args:\n",
    "        arr (np.ndarray): Array of shape (T_1, T_2).\n",
    "        axis (int): Axis along which to cumsum.\n",
    "    \"\"\"\n",
    "    A = arr.copy()\n",
    "    if axis==0:\n",
    "        for i in np.arange(A.shape[0]-2, -1, -1):\n",
    "            A[i, :] += A[i+1, :]\n",
    "    else: #axis==1\n",
    "        for i in np.arange(A.shape[1]-2, -1, -1):\n",
    "            A[:,i] += A[:,i+1]\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "@njit((nb.float64[:, ::1], nb.int64), fastmath=True, cache=True)\n",
    "def jitted_trunc_sig_kernel(nabla, order):\n",
    "    \"\"\"Given difference matrix nabla_ij = K[i+1, j+1] + K[i, j] - K[i+1, j] - K[i, j+1],\n",
    "    computes the truncated signature kernel of all orders up to 'order'.\"\"\"\n",
    "    B = np.ones((order+1, order+1, order+1, *nabla.shape))\n",
    "    for d in np.arange(order):\n",
    "        for n in np.arange(order-d):\n",
    "            for m in np.arange(order-d):\n",
    "                B[d+1,n,m] = 1 + nabla/(n+1)/(m+1)*B[d, n+1, m+1]\n",
    "                r1 = reverse_cumsum(nabla * B[d, n+1, 1] / (n+1), axis=0)\n",
    "                B[d+1,n,m, :-1, :] += r1[1:, :]\n",
    "                r2 = reverse_cumsum(nabla * B[d, 1, m+1] / (m+1), axis=1)\n",
    "                B[d+1,n,m, :, :-1] += r2[:, 1:]\n",
    "                rr = reverse_cumsum(nabla * B[d, 1, 1], axis=0)\n",
    "                rr = reverse_cumsum(rr, axis=1)\n",
    "                B[d+1,n,m, :-1, :-1] += rr[1:, 1:]\n",
    "\n",
    "    #copy, otherwise all memory accumulates in for loop\n",
    "    return B[1:,0,0,0,0].copy() \n",
    "\n",
    "\n",
    "\n",
    "def sig_kernel_gram(\n",
    "        X:List[np.ndarray],\n",
    "        Y:List[np.ndarray],\n",
    "        order:int,\n",
    "        static_kernel_gram:Callable,\n",
    "        only_last:bool = True,\n",
    "        sym:bool = False,\n",
    "        n_jobs:int = 1,\n",
    "        verbose:bool = False,\n",
    "    ):\n",
    "    \"\"\"Computes the Gram matrix k_sig(X_i, Y_j) of the signature kernel,\n",
    "    given the static kernel k(x, y) and the truncation order.\n",
    "\n",
    "    Args:\n",
    "        X (List[np.ndarray]): List of time series of shape (T_i, d).\n",
    "        Y (List[np.ndarray]): List of time series of shape (T_j, d).\n",
    "        order (int): Truncation level of the signature kernel.\n",
    "        static_kernel_gram (Callable): Gram kernel function taking in two ndarrays,\n",
    "                            see e.g. 'linear_kernel_gram' or 'rbf_kernel_gram'.\n",
    "        only_last (bool): If False, returns results of all truncation levels up to 'order'.\n",
    "        sym (bool): If True, computes the symmetric Gram matrix.\n",
    "        n_jobs (int): Number of parallel jobs to run.\n",
    "        verbose (bool): Whether to enable the tqdm progress bar.\n",
    "    \"\"\"\n",
    "    pairwise_ker = lambda s1, s2 : sig_kernel(s1, s2, order, static_kernel_gram, only_last)\n",
    "    return pairwise_kernel_gram(X, Y, pairwise_ker, sym, n_jobs, verbose)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
