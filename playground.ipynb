{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import sigkernel\n",
    "import os\n",
    "import sys\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "import ksig\n",
    "\n",
    "from kernels.abstract_base import TimeSeriesKernel, StaticKernel\n",
    "from kernels.static_kernels import LinearKernel, RBFKernel, PolyKernel\n",
    "from kernels.integral import StaticIntegralKernel\n",
    "from kernels.sig_pde import SigPDEKernel\n",
    "from kernels.sig_trunc import TruncSigKernel\n",
    "from kernels.gak import GlobalAlignmentKernel, sigma_gak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.29194314 0.11930961 ... 0.60271238 0.21530787 0.79389869]\n",
      " [0.29194314 1.         0.52197163 ... 0.10609314 0.29118823 0.35642461]\n",
      " [0.11930961 0.52197163 1.         ... 0.31442583 0.48875292 0.2727601 ]\n",
      " ...\n",
      " [0.60271238 0.10609314 0.31442583 ... 1.         0.39172966 0.65972546]\n",
      " [0.21530787 0.29118823 0.48875292 ... 0.39172966 1.         0.1116049 ]\n",
      " [0.79389869 0.35642461 0.2727601  ... 0.65972546 0.1116049  1.        ]]\n",
      "tensor([[ 1.0000, -0.2756, -0.2892,  ..., -0.1279, -0.1720,  0.3257],\n",
      "        [-0.2756,  1.0000,  0.2975,  ..., -0.3844, -0.4095, -0.0770],\n",
      "        [-0.2892,  0.2975,  1.0000,  ...,  0.0725, -0.2355,  0.0561],\n",
      "        ...,\n",
      "        [-0.1279, -0.3844,  0.0725,  ...,  1.0000,  0.0799,  0.2409],\n",
      "        [-0.1720, -0.4095, -0.2355,  ...,  0.0799,  1.0000, -0.7056],\n",
      "        [ 0.3257, -0.0770,  0.0561,  ...,  0.2409, -0.7056,  1.0000]],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "0.45113669473961154\n",
      "Execution time of function 2: 0.951037456999984\n",
      "Execution time of function 3: 0.4536024560002261\n"
     ]
    }
   ],
   "source": [
    "import ksig\n",
    "import timeit\n",
    "\n",
    "#### Test GAK ####\n",
    "N=200\n",
    "N2= 90\n",
    "T, d = 40, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "X_np = X.cpu().numpy()\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "sigma = tslearn.metrics.sigma_gak(X_np)\n",
    "gak = tslearn.metrics.cdist_gak\n",
    "# ksigker = ksig.kernels.GlobalAlignmentKernel(static_kernel=ksig.static.kernels.RBFKernel(bandwidth=sigma))\n",
    "# mine = GlobalAlignmentKernel(RBFKernel(sigma=sigma), normalize=True, max_batch=50000)\n",
    "# ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.RBFKernel(bandwidth=sigma), n_levels=5, order=1)\n",
    "# mine = TruncSigKernel(RBFKernel(sigma=sigma), normalize=False, trunc_level=5, geo_order=1, max_batch=50000)\n",
    "ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.LinearKernel(), n_levels=5, order=1)\n",
    "mine = TruncSigKernel(LinearKernel(), normalize=True, trunc_level=5, geo_order=1, max_batch=50000)\n",
    "\n",
    "\n",
    "#out = gak(X, X, sigma=sigma)\n",
    "out2 = ksigker(X_np, X_np)\n",
    "print(out2)\n",
    "out3 = mine(X, X)\n",
    "#print(out)\n",
    "print(out3)\n",
    "print(np.mean(np.abs(out2 - out3.cpu().numpy())))\n",
    "\n",
    "def function1():\n",
    "    gak(X, X_np, sigma=sigma)\n",
    "\n",
    "def function2():\n",
    "    ksigker(X_np, X_np)\n",
    "\n",
    "def function3():\n",
    "    with torch.no_grad():\n",
    "        mine(X, Y)\n",
    "\n",
    "# # Measure the execution time of function 1\n",
    "# execution_time1 = timeit.timeit(function1, number=1)\n",
    "\n",
    "# Measure the execution time of function 2\n",
    "execution_time2 = timeit.timeit(function2, number=1)\n",
    "print(\"Execution time of function 2:\", execution_time2)\n",
    "# Measure the execution time of function 3\n",
    "execution_time3 = timeit.timeit(function3, number=1)\n",
    "print(\"Execution time of function 3:\", execution_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for loop indices\n",
    "import time\n",
    "import torch\n",
    "import itertools\n",
    "from kernels.static_kernels import LinearKernel\n",
    "\n",
    "lin_ker = LinearKernel()\n",
    "\n",
    "def placeholder_ker(X:Tensor, Y:Tensor, diag:bool=False):\n",
    "    return lin_ker.time_gram(X, Y, diag)[...,0,0]\n",
    "\n",
    "\n",
    "def test_indices(X:Tensor, \n",
    "                 Y:Tensor,\n",
    "                 diag:bool,\n",
    "                max_batch:int, \n",
    "    ):\n",
    "    device = X.device\n",
    "    N1, T, d = X.shape\n",
    "    N2, _, _ = Y.shape\n",
    "\n",
    "    # split into batches. FASTEST METHOD NO BATCH\n",
    "    t1 = time.perf_counter()\n",
    "    result = placeholder_ker(X, Y)\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time NOBATCH\\t\", t1-t2)\n",
    "\n",
    "    # split into batches BY INDICES\n",
    "    t1 = time.perf_counter()\n",
    "    if diag:\n",
    "        indices = torch.arange(N1, device=device).tile(2,1) # shape (2, N)\n",
    "    else:\n",
    "        indices = torch.cartesian_prod(torch.arange(N1, device=device), \n",
    "                                    torch.arange(N2, device=device)).T #shape (2, N1*N2)\n",
    "    split = torch.split(indices, max_batch, dim=1)\n",
    "    result = [placeholder_ker(X[ix], Y[iy], diag=True) for ix,iy in split]\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time INDEX\\t\", t1-t2)\n",
    "\n",
    "    # split into batches VIA SPLIT\n",
    "    t1 = time.perf_counter()\n",
    "    split_X = torch.split(X, max_batch, dim=0)\n",
    "    Y_max_batch = max(1, max_batch//N1)\n",
    "    split_Y = torch.split(Y, Y_max_batch, dim=0)\n",
    "    result = [placeholder_ker(ix, iy) for ix,iy in itertools.product(split_X, split_Y)]\n",
    "    if max_batch >= N1:\n",
    "        result = torch.cat(result, dim=1)\n",
    "    else:\n",
    "        result = torch.cat(result, dim=0).reshape(N1, N2)\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time SPLIT\\t\", t1-t2)\n",
    "\n",
    "X = torch.randn(200, 7, 10)\n",
    "Y = torch.randn(300, 7, 10)\n",
    "test_indices(X, Y, False, 10000)\n",
    "\n",
    "#split = torch.split(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test dimensions of TimeSeriesKernels ####\n",
    "\n",
    "N=3\n",
    "N2=4\n",
    "T, d = 40, 5\n",
    "X = torch.randn(N, T, d, dtype=torch.float64) / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64) / d\n",
    "\n",
    "inputs = [\n",
    "    (X, X),\n",
    "    (X, Y),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "    (X[0], Y),\n",
    "    (X, Y[0]),\n",
    "]\n",
    "diag_inputs = [\n",
    "    (X, X),\n",
    "    (X, Y[:N]),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "]\n",
    "def test_kernel(ker: TimeSeriesKernel, inputs, diag=False):\n",
    "    print(ker)\n",
    "    for X, Y in inputs:\n",
    "        out = ker(X, Y, diag, normalize=False)\n",
    "        out_normalize = ker(X, Y, diag, normalize=True)\n",
    "        print(out)\n",
    "        print(out_normalize)\n",
    "        print(out.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "sigker = TruncSigKernel(static_kernel=RBFKernel(), \n",
    "                        trunc_level=4, \n",
    "                        geo_order=1,\n",
    "                        only_last=True,)\n",
    "test_kernel(sigker, inputs)\n",
    "test_kernel(sigker, diag_inputs, True)\n",
    "\n",
    "sigpde = SigPDEKernel(static_kernel=RBFKernel(),\n",
    "                     dyadic_order=3,)\n",
    "test_kernel(sigpde, inputs)\n",
    "test_kernel(sigpde, diag_inputs, True)\n",
    "\n",
    "intker = StaticIntegralKernel(static_kernel=RBFKernel())\n",
    "test_kernel(intker, inputs)\n",
    "test_kernel(intker, diag_inputs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "# Number of signature levels to use.\n",
    "n_levels = 5 \n",
    "\n",
    "# Use the RBF kernel for vector-valued data as static (base) kernel.\n",
    "static_kernel = ksig.static.kernels.RBFKernel() \n",
    "\n",
    "# Instantiate the signature kernel, which takes as input the static kernel.\n",
    "n_levels = 5\n",
    "order = 1\n",
    "sig_kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, static_kernel=static_kernel)\n",
    "\n",
    "# Generate 10 sequences of length 50 with 5 channels.\n",
    "n_seq, l_seq, n_feat = 10, 50, 5 \n",
    "X = np.random.randn(n_seq, l_seq, n_feat)\n",
    "\n",
    "# Sequence kernels take as input an array of sequences of ndim == 3,\n",
    "# and work as a callable for computing the kernel matrix. \n",
    "K_XX = sig_kernel(X)  # K_XX has shape (10, 10).\n",
    "\n",
    "# The diagonal kernel entries can also be computed.\n",
    "K_X = sig_kernel(X, diag=True)  # K_X has shape (10,).\n",
    "\n",
    "# Generate another array of 8 sequences of length 20 and 5 features.\n",
    "n_seq2, l_seq2 = 8, 20\n",
    "Y = np.random.randn(n_seq2, l_seq2, n_feat)\n",
    "\n",
    "# Compute the kernel matrix between arrays X and Y.\n",
    "K_XY = sig_kernel(X, Y)  # K_XY has shape (10, 8)\n",
    "K_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test that iisig gives the same result as mine\n",
    "import iisignature\n",
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "# Number of signature levels to use.\n",
    "normalize=False\n",
    "trunc_level = 5\n",
    "geo_order = 5\n",
    "N=2\n",
    "N2= 2\n",
    "T, d = 20, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "X_np = X.cpu().numpy()\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.LinearKernel(), \n",
    "                                       normalize=normalize,\n",
    "                                       n_levels=trunc_level, \n",
    "                                       order=geo_order)\n",
    "mine = TruncSigKernel(LinearKernel(scale=1), \n",
    "                      normalize=normalize, \n",
    "                      trunc_level=trunc_level, \n",
    "                      geo_order=geo_order, \n",
    "                      max_batch=50000)\n",
    "\n",
    "#test\n",
    "out1 = ksigker(X_np, Y_np)\n",
    "out2 = mine(X, Y)\n",
    "featuresX = iisignature.sig(X_np, trunc_level)\n",
    "featuresY = iisignature.sig(Y_np, trunc_level)\n",
    "out3 = 1+np.dot(featuresX, featuresY.T)\n",
    "print(\"ksig\", out1)\n",
    "print(\"\\nmine\", out2)\n",
    "print(\"\\niisig\", out3)\n",
    "print(np.mean(np.abs(out1 - out2.cpu().numpy())))\n",
    "print(np.mean(np.abs(out1 - out3)))\n",
    "print(np.mean(np.abs(out2.cpu().numpy() - out3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
