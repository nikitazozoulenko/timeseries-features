{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Any, Optional, Tuple, Literal, Callable\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import sigkernel\n",
    "import os\n",
    "import sys\n",
    "import tslearn\n",
    "import tslearn.metrics\n",
    "import ksig\n",
    "\n",
    "from kernels.abstract_base import TimeSeriesKernel, StaticKernel\n",
    "from kernels.static_kernels import LinearKernel, RBFKernel, PolyKernel\n",
    "from kernels.integral import StaticIntegralKernel\n",
    "from kernels.sig_pde import SigPDEKernel\n",
    "from kernels.sig_trunc import TruncSigKernel\n",
    "from kernels.gak import GlobalAlignmentKernel, sigma_gak\n",
    "from kernels.flattened_static import FlattenedStaticKernel\n",
    "from kernels.reservoir import ReservoirKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ksig\n",
    "import timeit\n",
    "\n",
    "#### Test GAK ####\n",
    "N= 80\n",
    "N2= 500\n",
    "T, d = 70, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N,  T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "X_np = X.cpu().numpy()\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "sigma = tslearn.metrics.sigma_gak(X_np)\n",
    "gak = tslearn.metrics.cdist_gak\n",
    "ksigker = ksig.kernels.GlobalAlignmentKernel(static_kernel=ksig.static.kernels.RBFKernel(bandwidth=sigma))\n",
    "mine = GlobalAlignmentKernel(RBFKernel(sigma=sigma), normalize=True, max_batch=50000)\n",
    "# ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.RBFKernel(bandwidth=sigma), n_levels=5, order=1)\n",
    "# mine = TruncSigKernel(RBFKernel(sigma=sigma), normalize=False, trunc_level=5, geo_order=1, max_batch=50000)\n",
    "# ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.LinearKernel(), n_levels=5, order=1)\n",
    "# mine = TruncSigKernel(LinearKernel(), normalize=True, trunc_level=5, geo_order=1, max_batch=50000)\n",
    "\n",
    "\n",
    "#out = gak(X, X, sigma=sigma)\n",
    "out2 = ksigker(X_np, X_np)\n",
    "print(out2)\n",
    "out3 = mine(X, X)\n",
    "#print(out)\n",
    "print(out3)\n",
    "print(np.mean(np.abs(out2 - out3.cpu().numpy())))\n",
    "\n",
    "def function1():\n",
    "    gak(X, X_np, sigma=sigma)\n",
    "\n",
    "def function2():\n",
    "    ksigker(X_np, X_np)\n",
    "\n",
    "def function3():\n",
    "    with torch.no_grad():\n",
    "        mine(X, Y)\n",
    "\n",
    "# # Measure the execution time of function 1\n",
    "# execution_time1 = timeit.timeit(function1, number=1)\n",
    "\n",
    "# Measure the execution time of function 2\n",
    "execution_time2 = timeit.timeit(function2, number=1)\n",
    "print(\"Execution time of function 2:\", execution_time2)\n",
    "# Measure the execution time of function 3\n",
    "execution_time3 = timeit.timeit(function3, number=1)\n",
    "print(\"Execution time of function 3:\", execution_time3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over antidiagonals with s,t>0\n",
    "T1 = 5\n",
    "T2 = 4\n",
    "for diag in range(2, T1+T2-1):\n",
    "    for s in range(max(1, diag - T2 + 1), min(diag, T1)):\n",
    "        t = diag - s\n",
    "        print(s,t)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for loop indices\n",
    "import time\n",
    "import torch\n",
    "import itertools\n",
    "from kernels.static_kernels import LinearKernel\n",
    "\n",
    "lin_ker = LinearKernel()\n",
    "\n",
    "def placeholder_ker(X:Tensor, Y:Tensor, diag:bool=False):\n",
    "    return lin_ker.time_gram(X, Y, diag)[...,0,0]\n",
    "\n",
    "\n",
    "def test_indices(X:Tensor, \n",
    "                 Y:Tensor,\n",
    "                 diag:bool,\n",
    "                max_batch:int, \n",
    "    ):\n",
    "    device = X.device\n",
    "    N1, T, d = X.shape\n",
    "    N2, _, _ = Y.shape\n",
    "\n",
    "    # split into batches. FASTEST METHOD NO BATCH\n",
    "    t1 = time.perf_counter()\n",
    "    result = placeholder_ker(X, Y)\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time NOBATCH\\t\", t1-t2)\n",
    "\n",
    "    # split into batches BY INDICES\n",
    "    t1 = time.perf_counter()\n",
    "    if diag:\n",
    "        indices = torch.arange(N1, device=device).tile(2,1) # shape (2, N)\n",
    "    else:\n",
    "        indices = torch.cartesian_prod(torch.arange(N1, device=device), \n",
    "                                    torch.arange(N2, device=device)).T #shape (2, N1*N2)\n",
    "    split = torch.split(indices, max_batch, dim=1)\n",
    "    result = [placeholder_ker(X[ix], Y[iy], diag=True) for ix,iy in split]\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time INDEX\\t\", t1-t2)\n",
    "\n",
    "    # split into batches VIA SPLIT\n",
    "    t1 = time.perf_counter()\n",
    "    split_X = torch.split(X, max_batch, dim=0)\n",
    "    Y_max_batch = max(1, max_batch//N1)\n",
    "    split_Y = torch.split(Y, Y_max_batch, dim=0)\n",
    "    result = [placeholder_ker(ix, iy) for ix,iy in itertools.product(split_X, split_Y)]\n",
    "    if max_batch >= N1:\n",
    "        result = torch.cat(result, dim=1)\n",
    "    else:\n",
    "        result = torch.cat(result, dim=0).reshape(N1, N2)\n",
    "    t2 = time.perf_counter()\n",
    "    print(\"time SPLIT\\t\", t1-t2)\n",
    "\n",
    "X = torch.randn(200, 7, 10)\n",
    "Y = torch.randn(300, 7, 10)\n",
    "test_indices(X, Y, False, 10000)\n",
    "\n",
    "#split = torch.split(X, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kernels.sig_trunc.TruncSigKernel object at 0x7faf979210d0>\n",
      "torch.Size([3, 3, 6])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([1, 1, 6])\n",
      "torch.Size([1, 1, 6])\n",
      "torch.Size([1, 4, 6])\n",
      "torch.Size([3, 1, 6])\n",
      "\n",
      "<kernels.sig_trunc.TruncSigKernel object at 0x7faf979210d0>\n",
      "torch.Size([3, 6])\n",
      "torch.Size([4, 6])\n",
      "torch.Size([3, 6])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([1, 6])\n",
      "\n",
      "<kernels.sig_pde.SigPDEKernel object at 0x7faf9792e810>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.sig_pde.SigPDEKernel object at 0x7faf9792e810>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<kernels.integral.StaticIntegralKernel object at 0x7faf9792fb10>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.integral.StaticIntegralKernel object at 0x7faf9792fb10>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<kernels.sig_pde.SigPDEKernel object at 0x7faf9792dc10>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.sig_pde.SigPDEKernel object at 0x7faf9792dc10>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<kernels.gak.GlobalAlignmentKernel object at 0x7faf97896ad0>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.gak.GlobalAlignmentKernel object at 0x7faf97896ad0>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<kernels.flattened_static.FlattenedStaticKernel object at 0x7fafbcca6090>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.flattened_static.FlattenedStaticKernel object at 0x7fafbcca6090>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n",
      "<kernels.reservoir.ReservoirKernel object at 0x7faf97e4af90>\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([3, 1])\n",
      "\n",
      "<kernels.reservoir.ReservoirKernel object at 0x7faf97e4af90>\n",
      "torch.Size([3])\n",
      "torch.Size([4])\n",
      "torch.Size([3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### test dimensions of TimeSeriesKernels ####\n",
    "\n",
    "N=3\n",
    "N2=4\n",
    "T, d = 7, 5\n",
    "X = torch.randn(N, T, d) / d**0.5\n",
    "Y = torch.randn(N2, T, d) / d**0.5\n",
    "inputs = [\n",
    "    (X, X),\n",
    "    (X, Y),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "    (X[0], Y),\n",
    "    (X, Y[0]),\n",
    "]\n",
    "diag_inputs = [\n",
    "    (X, X),\n",
    "    (Y, Y),\n",
    "    (X[:min(N,N2)], Y[:min(N,N2)]),\n",
    "    (X[0], X[0]),\n",
    "    (X[0], Y[0]),\n",
    "]\n",
    "def test_kernel(ker: TimeSeriesKernel, inputs, diag=False):\n",
    "    print(ker)\n",
    "    for X, Y in inputs:\n",
    "        out = ker(X, Y, diag, normalize=False)\n",
    "        out_normalize = ker(X, Y, diag, normalize=True)\n",
    "        # print(out, \"out\")\n",
    "        # print(out_normalize, \"out, normalize\")\n",
    "        print(out.shape)\n",
    "    print()\n",
    "\n",
    "\n",
    "sigker = TruncSigKernel(static_kernel=RBFKernel(), \n",
    "                        trunc_level=6, \n",
    "                        geo_order=1,\n",
    "                        only_last=False,)\n",
    "test_kernel(sigker, inputs)\n",
    "test_kernel(sigker, diag_inputs, True)\n",
    "\n",
    "sigpde = SigPDEKernel(static_kernel=RBFKernel(),\n",
    "                     dyadic_order=3,)\n",
    "test_kernel(sigpde, inputs)\n",
    "test_kernel(sigpde, diag_inputs, True)\n",
    "\n",
    "intker = StaticIntegralKernel(static_kernel=RBFKernel())\n",
    "test_kernel(intker, inputs)\n",
    "test_kernel(intker, diag_inputs, True)\n",
    "\n",
    "pde = SigPDEKernel(static_kernel=RBFKernel(), dyadic_order=2)\n",
    "test_kernel(pde, inputs)\n",
    "test_kernel(pde, diag_inputs, True)\n",
    "\n",
    "gak = GlobalAlignmentKernel(static_kernel=RBFKernel(sigma=sigma_gak(X)))\n",
    "test_kernel(gak, inputs)\n",
    "test_kernel(gak, diag_inputs, True)\n",
    "\n",
    "flat = FlattenedStaticKernel(static_kernel=LinearKernel())\n",
    "test_kernel(flat, inputs)\n",
    "test_kernel(flat, diag_inputs, True)\n",
    "\n",
    "res = ReservoirKernel()\n",
    "test_kernel(res, inputs)\n",
    "test_kernel(res, diag_inputs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "# Number of signature levels to use.\n",
    "n_levels = 5 \n",
    "\n",
    "# Use the RBF kernel for vector-valued data as static (base) kernel.\n",
    "static_kernel = ksig.static.kernels.RBFKernel() \n",
    "\n",
    "# Instantiate the signature kernel, which takes as input the static kernel.\n",
    "n_levels = 5\n",
    "order = 1\n",
    "sig_kernel = ksig.kernels.SignatureKernel(n_levels=n_levels, order=order, static_kernel=static_kernel)\n",
    "\n",
    "# Generate 10 sequences of length 50 with 5 channels.\n",
    "n_seq, l_seq, n_feat = 10, 50, 5 \n",
    "X = np.random.randn(n_seq, l_seq, n_feat)\n",
    "\n",
    "# Sequence kernels take as input an array of sequences of ndim == 3,\n",
    "# and work as a callable for computing the kernel matrix. \n",
    "K_XX = sig_kernel(X)  # K_XX has shape (10, 10).\n",
    "\n",
    "# The diagonal kernel entries can also be computed.\n",
    "K_X = sig_kernel(X, diag=True)  # K_X has shape (10,).\n",
    "\n",
    "# Generate another array of 8 sequences of length 20 and 5 features.\n",
    "n_seq2, l_seq2 = 8, 20\n",
    "Y = np.random.randn(n_seq2, l_seq2, n_feat)\n",
    "\n",
    "# Compute the kernel matrix between arrays X and Y.\n",
    "K_XY = sig_kernel(X, Y)  # K_XY has shape (10, 8)\n",
    "K_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test that iisig gives the same result as mine\n",
    "import iisignature\n",
    "import numpy as np\n",
    "import ksig\n",
    "\n",
    "# Number of signature levels to use.\n",
    "normalize=False\n",
    "trunc_level = 5\n",
    "geo_order = 5\n",
    "N=2\n",
    "N2= 2\n",
    "T, d = 20, 2\n",
    "torch.manual_seed(0)\n",
    "X = torch.randn(N, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "Y = torch.randn(N2, T, d, dtype=torch.float64).to(\"cuda\") / d\n",
    "X_np = X.cpu().numpy()\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "ksigker = ksig.kernels.SignatureKernel(static_kernel=ksig.static.kernels.LinearKernel(), \n",
    "                                       normalize=normalize,\n",
    "                                       n_levels=trunc_level, \n",
    "                                       order=geo_order)\n",
    "mine = TruncSigKernel(LinearKernel(scale=1), \n",
    "                      normalize=normalize, \n",
    "                      trunc_level=trunc_level, \n",
    "                      geo_order=geo_order, \n",
    "                      max_batch=50000)\n",
    "\n",
    "#test\n",
    "out1 = ksigker(X_np, Y_np)\n",
    "out2 = mine(X, Y)\n",
    "featuresX = iisignature.sig(X_np, trunc_level)\n",
    "featuresY = iisignature.sig(Y_np, trunc_level)\n",
    "out3 = 1+np.dot(featuresX, featuresY.T)\n",
    "print(\"ksig\", out1)\n",
    "print(\"\\nmine\", out2)\n",
    "print(\"\\niisig\", out3)\n",
    "print(np.mean(np.abs(out1 - out2.cpu().numpy())))\n",
    "print(np.mean(np.abs(out1 - out3)))\n",
    "print(np.mean(np.abs(out2.cpu().numpy() - out3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
